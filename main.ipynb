{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caltrans Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to extract relevant data from text files, previously converted from PDF files. Since the text files are quite structured, the decision is to use regex to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install the following packages if you don't have them yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas numpy tqdm ipykernel notebook python-dotenv openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import List, Tuple\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# pd.set_option('display.max_rows', None)  # optional to see all rows in DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either change the hard-coded path of assign user path path to raw data in .env file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "RAW_DATA_PATH = Path(os.getenv('RAW_DATA_PATH'))\n",
    "if not RAW_DATA_PATH.exists():\n",
    "    RAW_DATA_PATH = Path('./RR Procurement - Raw Data')\n",
    "    if not RAW_DATA_PATH.exists():\n",
    "        raise ValueError('Make sure to set a path to raw data in the .env file or copy data into root of the repo')\n",
    "print(f'Current RAW_DATA_PATH is {RAW_DATA_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rest of the paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = RAW_DATA_PATH.parent / 'results'\n",
    "RESULTS_PATH.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "OUTLIERS_PATH = RESULTS_PATH / 'outliers'\n",
    "\n",
    "RAW_DATA_PATH_PDF = RAW_DATA_PATH / 'PDFs'\n",
    "OUTLIERS_PATH_PDF = OUTLIERS_PATH / 'PDFs'\n",
    "OUTLIERS_PATH_PDF.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "RAW_DATA_PATH_LINEPRINTER = RAW_DATA_PATH / 'Txt files - lineprinter'\n",
    "OUTLIERS_PATH_LINEPRINTER = OUTLIERS_PATH / 'Txt files - lineprinter'\n",
    "OUTLIERS_PATH_LINEPRINTER.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define column names so we don't use literals at any point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTIFIER = \"Identifier\"\n",
    "POSTPONED_CONTRACT = \"Postponed_Contract\"\n",
    "NUMBER_OF_BIDDERS = \"Number_of_Bidders\"\n",
    "BID_OPENING_DATE = \"Bid_Opening_Date\"\n",
    "CONTRACT_DATE = \"Contract_Date\"\n",
    "CONTRACT_NUMBER = \"Contract_Number\"\n",
    "TOTAL_NUMBER_OF_WORKING_DAYS = \"Total_Number_of_Working_Days\"\n",
    "CONTRACT_ITEMS = \"Number_of_Contract_Items\"\n",
    "CONTRACT_DESCRIPTION = \"Contract_Description\"\n",
    "PERCENT_OVER_EST = \"Percent_Est_Over\"\n",
    "PERCENT_UNDER_EST = \"Percent_Est_Under\"\n",
    "ENGINEERS_EST = \"Engineers_Est\"\n",
    "AMOUNT_OVER = \"Amount_Over\"\n",
    "AMOUNT_UNDER = \"Amount_Under\"\n",
    "CONTRACT_CODE = \"Contract_Code\"\n",
    "\n",
    "BID_RANK = \"Bid_Rank\"\n",
    "A_PLUS_B_INDICATOR = \"A_plus_B_indicator\"\n",
    "BID_TOTAL = \"Bid_Total\"   \n",
    "BIDDER_ID = \"Bidder_ID\"\n",
    "BIDDER_NAME = \"Bidder_Name\"\n",
    "CSLB_NUMBER = \"CSLB_Number\"\n",
    "\n",
    "SUBCONTRACTOR_NAME = \"Subcontractor_Name\"\n",
    "SUBCONTRACTED_LINE_ITEM = \"Subcontracted_Line_Item\"\n",
    "\n",
    "ITEM_NUMBER = \"Item_Number\"\n",
    "ITEM_CODE = \"Item_Code\"\n",
    "ITEM_DESCRIPTION = \"Item_Description\"\n",
    "ITEM_DOLLAR_AMOUNT = \"Item_Dollar_Amount\"\n",
    "\n",
    "CITY = \"City\"\n",
    "SUBCONTRACTOR_LICENSE_NUMBER = \"Subcontractor_License_Number\"\n",
    "\n",
    "COULD_NOT_PARSE = \"COULD NOT PARSE\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core functions\n",
    "\n",
    "The following are the core functions that will be used to extract the data from the text files (maybe move to separate python file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_contract_number_and_tag_from_filename(filename:str) -> Tuple[str, str]:\n",
    "    pattern = re.compile(r\"^(\\d{2}-\\w+)\\.pdf_(\\d+)$\", re.IGNORECASE)  # IGNORECASE is critical since names might have both PDF and pdf\n",
    "    match = pattern.search(filename)\n",
    "    contract_number, tag = match.groups()\n",
    "    identifier = f\"{contract_number}_{tag}\"\n",
    "    return contract_number, tag, identifier\n",
    "\n",
    "\n",
    "def get_contract_number(file_contents):\n",
    "    return extract(file_contents, r\"CONTRACT NUMBER\\s+([A-Za-z0-9-]+)\")\n",
    "\n",
    "\n",
    "def get_dates(file_contents):\n",
    "    match = re.search(r\"BID OPENING DATE\\s+(\\d+\\/\\d+\\/\\d+).+\\s+(\\d+\\/\\d+\\/\\d+)\", file_contents)\n",
    "    return match.group(1), match.group(2)\n",
    "    \n",
    "\n",
    "def extract(file_contents, regex):\n",
    "    # Search for the pattern in the text\n",
    "    match = re.search(regex, file_contents)\n",
    "\n",
    "    if match:\n",
    "        # Extract first capture group\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "def extract_contract_data(file_contents, identifier):\n",
    "    row = defaultdict(str)\n",
    "    row[IDENTIFIER] = identifier\n",
    "    match = extract(file_contents, r\"(POSTPONED CONTRACT)\")\n",
    "    row[POSTPONED_CONTRACT] = 1 if match else 0\n",
    "    row[BID_OPENING_DATE], row[CONTRACT_DATE] = get_dates(file_contents)\n",
    "    row[CONTRACT_CODE] = extract(file_contents, r\"CONTRACT CODE\\s+'([^']+)'\")  # check\n",
    "    row[CONTRACT_ITEMS] = extract(file_contents, r\"(\\d+)\\s+CONTRACT ITEMS\")\n",
    "    row[TOTAL_NUMBER_OF_WORKING_DAYS] = extract(file_contents, r\"TOTAL NUMBER OF WORKING DAYS\\s+(\\d+)\")\n",
    "    row[NUMBER_OF_BIDDERS] = extract(file_contents, r\"NUMBER OF BIDDERS\\s+(\\d+)\")\n",
    "    row[ENGINEERS_EST] = extract(file_contents, r\"ENGINEERS EST\\s+([\\d,]+\\.\\d{2})\")\n",
    "    row[AMOUNT_OVER] = extract(file_contents, r\"AMOUNT OVER\\s+([\\d,]+\\.\\d{2})\")\n",
    "    row[AMOUNT_UNDER] = extract(file_contents, r\"AMOUNT UNDER\\s+([\\d,]+\\.\\d{2})\")\n",
    "    row[PERCENT_OVER_EST] = extract(file_contents, r\"PERCENT OVER EST\\s+(\\d+.\\d{2})\")\n",
    "    row[PERCENT_UNDER_EST] = extract(file_contents, r\"PERCENT UNDER EST\\s+(\\d+.\\d{2})\")\n",
    "    row[CONTRACT_DESCRIPTION] = extract(file_contents, r\"(?:\\n)?(.*?)FEDERAL AID\").strip()\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def extract_contract_bid_data(file_contents, identifier):\n",
    "    \n",
    "    # have fixed width for name (37 characters) and CSLB number (8 digits)\n",
    "    pattern = re.compile(r\"(\\d+)\\s+(A\\))?\\s+([\\d,]+\\.\\d{2})\\s+(\\d+)\\s+(.{37})\\s(\\d{3} \\d{3}-\\d{4})(.*)?$\\s+(.*?)(.{37})\\s(\\d{8})\", re.MULTILINE)\n",
    "    matches = pattern.findall(file_contents)\n",
    "    \n",
    "    contract_bid_data = []\n",
    "\n",
    "    for match in matches:\n",
    "        row = defaultdict(str)\n",
    "        row[IDENTIFIER] = identifier\n",
    "        row[BID_RANK] = match[0]\n",
    "        row[A_PLUS_B_INDICATOR] = 1 if match[1] else 0\n",
    "        row[BID_TOTAL] = match[2]\n",
    "        row[BIDDER_ID] = match[3].strip()\n",
    "        row[BIDDER_NAME] = match[4].strip()\n",
    "        row[\"Bidder_Phone\"] = match[5].strip()\n",
    "        row[\"Extra\"] = match[6]\n",
    "        row['Weird_Contract_Notes'] = match[7]\n",
    "        row[BIDDER_NAME] += ' ' + match[8]\n",
    "        row[BIDDER_NAME] = row[BIDDER_NAME].strip()\n",
    "        row[CSLB_NUMBER] = match[9] \n",
    "        contract_bid_data.append(row)\n",
    "\n",
    "\n",
    "    # if contract has A+B we need to correct the BID_TOTAL:\n",
    "    pattern = re.compile(r\"A\\+B\\)\\s+([\\d,]+\\.\\d{2})\", re.MULTILINE)  # this will find many A+B) matches but it is reasonable to expect that first A+B) matches are all we need\n",
    "    a_plus_b_bids = pattern.findall(file_contents)\n",
    "    if a_plus_b_bids:\n",
    "        for i, a_plus_b_bid in zip(range(len(contract_bid_data)), a_plus_b_bids):  # this does truncation of a_plus_b_bids list \n",
    "            contract_bid_data[i][BID_TOTAL] = a_plus_b_bid\n",
    "\n",
    "    return contract_bid_data\n",
    "\n",
    "\n",
    "def extract_bid_subcontractor_data(file_contents, identifier):\n",
    "    \"\"\"\n",
    "    We extract data in two steps.\n",
    "    1) First we get the relevant information from a whole contract using pattern1:\n",
    "    \"X(.*?)(?=X|Y|Z)\"\n",
    "    this means starting phrase must be X, then text that we want extracted and then the match can either finish with X, Y or Z.\n",
    "    In our case:\n",
    "    X = BIDDER ID NAME AND ADDRESS LICENSE NUMBER DESCRIPTION OF PORTION OF WORK SUBCONTRACTED\n",
    "    Y = \\f (this is a new page character, in the text is denoted as FF, but this is not a pure FF text but /f)\n",
    "    Z = CONTINUED ON NEXT PAGE\n",
    "\n",
    "    I also ensure that we are doing positive lookahead (using ?=), so the matches do not overlap.\n",
    "\n",
    "    2) The second step is to exact the columns, we use some fixed with columns for that in pattern2.\n",
    "    \"\"\"\n",
    "\n",
    "    pattern1= re.compile(r\"(?s)BIDDER ID NAME AND ADDRESS\\s+LICENSE NUMBER\\s+DESCRIPTION OF PORTION OF WORK SUBCONTRACTED(.*?)(?=BIDDER ID NAME AND ADDRESS\\s+LICENSE NUMBER\\s+DESCRIPTION OF PORTION OF WORK SUBCONTRACTED|\\f|CONTINUED ON NEXT PAGE)\")\n",
    "    matches1 = pattern1.findall(file_contents)\n",
    "    if not matches1:\n",
    "        return []\n",
    "            \n",
    "    bid_subcontractor_data = []\n",
    "    for match1 in matches1:\n",
    "        pattern2 = re.compile(r\"(?m)^\\s+(\\d{2})?\\s+(.{58})\\s+(.+)\\n\\s+(.{38})?(.+)\")\n",
    "        \n",
    "        matches2 = pattern2.findall(match1)\n",
    "        \n",
    "        for match2 in matches2:\n",
    "            row = defaultdict(str)\n",
    "            row[IDENTIFIER] = identifier\n",
    "            row[BIDDER_ID] = match2[0]\n",
    "            row[SUBCONTRACTOR_NAME] = match2[1].strip()\n",
    "            row[SUBCONTRACTED_LINE_ITEM] = match2[2]\n",
    "            row[CITY] = match2[3].strip()\n",
    "            row[SUBCONTRACTOR_LICENSE_NUMBER] = match2[4].strip()\n",
    "            \n",
    "            bid_subcontractor_data.append(row)\n",
    "\n",
    "    return bid_subcontractor_data\n",
    "\n",
    "\n",
    "def extract_contract_line_item_data(file_contents, identifier):\n",
    "\n",
    "    pattern = re.compile(r\"(?m)^\\s+(\\d+)\\s+(\\(F\\))?\\s+(\\d+)\\s+(.{45})\\s+(.{35})\\s+([\\d,]+\\.\\d{2})(?:\\n\\s{26}(.+)\\n)?\")\n",
    "\n",
    "    matches = pattern.findall(file_contents)\n",
    "\n",
    "    contract_line_item_data = []\n",
    "    for match in matches:\n",
    "        row = defaultdict(str)\n",
    "        row[IDENTIFIER] = identifier\n",
    "        row[ITEM_NUMBER] = match[0]\n",
    "        row[\"Extra\"] = match[1]\n",
    "        row[ITEM_CODE] = match[2]\n",
    "        row[ITEM_DESCRIPTION] = match[3].strip() + ' ' + match[6]\n",
    "        row[ITEM_DOLLAR_AMOUNT] = match[5]\n",
    "        contract_line_item_data.append(row)\n",
    "        \n",
    "    contract_line_item_data\n",
    "    return contract_line_item_data\n",
    "\n",
    "def fill_gaps_in_bidder_id(df):\n",
    "    df[BIDDER_ID] = df[BIDDER_ID].replace('', np.nan)\n",
    "    df[BIDDER_ID] = df[BIDDER_ID].ffill()\n",
    "    return df\n",
    "\n",
    "def write_to_results(df: pd.DataFrame | List, name: str, timestamp=None):\n",
    "    if isinstance(df, list):\n",
    "        df = pd.DataFrame(df)\n",
    "    \n",
    "    if timestamp:\n",
    "        df.to_csv(RESULTS_PATH / f'{timestamp}_{name}.csv', index=False)\n",
    "    else:\n",
    "        df.to_csv(RESULTS_PATH / f'{name}.csv', index=False)\n",
    "    \n",
    "\n",
    "def read_file(filepath: str):\n",
    "    # Open the file in read mode ('r')\n",
    "    with open(filepath, 'r') as file:\n",
    "        # Read the contents of the file into a string\n",
    "        file_contents = file.read()\n",
    "    return file_contents\n",
    "\n",
    "\n",
    "def expand_ranges_in_subcontracted_line_item(line: str) -> str:\n",
    "    \"\"\"\n",
    "    For example: takes a \"6-8, 13-15\" and converts to \"6, 7, 8, 13, 14, 15\".\n",
    "    Converts NaN to empty string.\n",
    "    \"\"\"\n",
    "    if pd.isnull(line):\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        # Split the string by commas to separate different ranges/groups\n",
    "        parts = str(line).split(',')\n",
    "        # Initialize an empty list to store all numbers\n",
    "        all_numbers = []\n",
    "        \n",
    "        for part in parts:\n",
    "            # Strip whitespace and check if part contains a range (indicated by '-')\n",
    "            if '-' in part:\n",
    "                start, end = map(int, part.split('-'))\n",
    "                # Add all numbers in this range (inclusive) to the list\n",
    "                all_numbers.extend(range(start, end + 1))\n",
    "            else:\n",
    "                # If not a range, just add the single number\n",
    "                all_numbers.append(int(part.strip()))\n",
    "        \n",
    "        # Return a comma-separated string of all_numbers\n",
    "        return \", \".join(map(str, all_numbers))\n",
    "    except:\n",
    "        return COULD_NOT_PARSE\n",
    "    \n",
    "\n",
    "def parse_subcontracted_line_item(df):\n",
    "    \"\"\"\n",
    "    Takes a Subcontracted_Line_Item in df, and splits into three columns: Y1, Y2, Y3.\n",
    "    For example \"SOME TEXT ITEMS 6 THRU 8 AND 13 THRU 15 (PARTIALS)\", will be split into:\n",
    "    - SOME TEXT, \n",
    "    - ITEMS, \n",
    "    - 6 THRU 8 AND 13 THRU 15, \n",
    "    - (PARTIALS)\n",
    "    Next, the \"6 THRU 8 AND 13 THRU 15\" will be converted into \"6-8, 13-15\" and then expanded to \"6, 7, 8, 13, 14, 15\".\n",
    "    \"\"\"\n",
    "    # splits subcontracted line item into three columns\n",
    "    df[['PARSED_1', 'PARSED_2', 'PARSED_3', 'PARSED_4']] = df[SUBCONTRACTED_LINE_ITEM].str.extract(r\"^(.+?)?(ITEMS|ITEM NUMBERS|ITEM\\(S\\):|ITEM)(.+?)(\\(.+\\))?$\")\n",
    "    # replace the 'THRU' and 'AND' with '-' and ','\n",
    "    df['PARSED_3'] = df['PARSED_3'].str.replace('THRU', '-', regex=False).str.replace('AND', ',', regex=False).str.replace('&', ',', regex=False)\n",
    "    # extend all the ranges\n",
    "    df['PARSED_5'] = df['PARSED_3'].apply(expand_ranges_in_subcontracted_line_item)\n",
    "    df_outliers = df[df['PARSED_5'] == COULD_NOT_PARSE]\n",
    "    return df, df_outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test parse_subcontracted_line_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('subcontracted_line_item_examples.txt', header=None, delimiter=\"\\t\", names=['Subcontracted_Line_Item'])\n",
    "df, df_outlier = parse_subcontracted_line_item(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One sample study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = RAW_DATA_PATH.parent / 'sample' / '01-0A3804.pdf_2724.txt'\n",
    "# filepath = RAW_DATA_PATH_LINEPRINTER / '01-0A3804.pdf_4353.txt'\n",
    "# filepath = RAW_DATA_PATH_LINEPRINTER / '01-0A0904.pdf_2724.txt'\n",
    "# filepath = RAW_DATA_PATH_LINEPRINTER / '01-0A1204.pdf_11468.txt'\n",
    "# filepath = RAW_DATA_PATH_LINEPRINTER / '01-0F4304.pdf_12346.txt'  # issue # 11\n",
    "# filepath = RAW_DATA_PATH_LINEPRINTER / '01-0K6104.pdf_12731.txt'  # issue # 9\n",
    "# filepath = RAW_DATA_PATH_LINEPRINTER / '01-0K4604.pdf_12040.txt'  # issue # 1\n",
    "# filepath = RAW_DATA_PATH_LINEPRINTER / '01-0H3204.pdf_9871.txt'  # issue # 5\n",
    "filepath = RAW_DATA_PATH_LINEPRINTER / '01-0A0404.pdf_10165.txt'  # issue # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_number_from_filename, tag, identifier = get_contract_number_and_tag_from_filename(filepath.stem)\n",
    "\n",
    "file_contents = read_file(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_number_from_filename, tag, identifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract contract data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contract_data = pd.DataFrame([extract_contract_data(file_contents, identifier)])\n",
    "df_contract_bid_data = pd.DataFrame(extract_contract_bid_data(file_contents, identifier))\n",
    "df_bid_subcontractor_data = parse_subcontracted_line_item(fill_gaps_in_bidder_id(pd.DataFrame(extract_bid_subcontractor_data(file_contents, identifier))))\n",
    "df_contract_line_item_data = pd.DataFrame(extract_contract_line_item_data(file_contents, identifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contract_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contract_bid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bid_subcontractor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None, \n",
    "#                        'display.max_columns', None, \n",
    "#                        'display.width', None, \n",
    "#                        'display.max_colwidth', None):\n",
    "df_contract_line_item_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we run a batch or a single file (for example, if you want to run a specific outlier, make `files` a single element list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = (RAW_DATA_PATH/'Txt files - lineprinter').glob('*.txt')\n",
    "# files = [RAW_DATA_PATH/'Txt files - lineprinter'/'01-0F9204.PDF_12364.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_data = []\n",
    "contract_bid_data = []\n",
    "bid_subcontractor_data = []\n",
    "contract_line_item_data = []\n",
    "other_format = []\n",
    "\n",
    "for filepath in tqdm(files):\n",
    "    \n",
    "    file_contents = read_file(filepath)\n",
    "        \n",
    "    filename = filepath.stem\n",
    "    contract_number_from_filename, tag, identifier = get_contract_number_and_tag_from_filename(filename)\n",
    "    contract_number_from_contents = get_contract_number(file_contents)\n",
    "    \n",
    "    if contract_number_from_filename == contract_number_from_contents:  \n",
    "        contract_data.append(extract_contract_data(file_contents, identifier))\n",
    "        contract_bid_data.extend(extract_contract_bid_data(file_contents, identifier))\n",
    "        bid_subcontractor_data.extend(extract_bid_subcontractor_data(file_contents, identifier))\n",
    "        contract_line_item_data.extend(extract_contract_line_item_data(file_contents, identifier))\n",
    "    else:\n",
    "        # if contract number doesn't match then something is off that needs investigation\n",
    "        other_format.append({'other_format_filename': filename})\n",
    "        # let's also copy the pdf to a folder for manual inspection\n",
    "        source_path = RAW_DATA_PATH_PDF / f'{filename}.pdf'\n",
    "        destination_path = OUTLIERS_PATH_PDF / f'{filename}.pdf'\n",
    "        shutil.copy(source_path, destination_path)\n",
    "        \n",
    "        source_path = RAW_DATA_PATH_LINEPRINTER / f'{filename}.txt'\n",
    "        destination_path = OUTLIERS_PATH_LINEPRINTER / f'{filename}.txt'\n",
    "        shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the timestamp line if you want to save all files with the timstampt prefix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp = datetime.strftime(datetime.now(), '%m-%d-%Y-%H:%M:%S')\n",
    "timestamp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_results(contract_data, \"contract_data\", timestamp=timestamp)\n",
    "write_to_results(contract_bid_data, \"contract_bid_data\", timestamp=timestamp)\n",
    "\n",
    "df_bid_subcontractor_data, df_bid_subcontractor_data_could_not_parse = parse_subcontracted_line_item(\n",
    "    fill_gaps_in_bidder_id(pd.DataFrame(bid_subcontractor_data)))\n",
    "\n",
    "write_to_results(df_bid_subcontractor_data, \"bid_subcontractor_data\", timestamp=timestamp)\n",
    "write_to_results(df_bid_subcontractor_data_could_not_parse, \"bid_subcontractor_outliers\", timestamp=timestamp)\n",
    "\n",
    "write_to_results(contract_line_item_data, \"contract_line_item_data\", timestamp=timestamp)\n",
    "write_to_results(other_format, \"other_format\", timestamp=timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your CSV files\n",
    "csv_file_paths = RESULTS_PATH.glob('*.csv')\n",
    "\n",
    "# Path to the output Excel file\n",
    "excel_file_path = RESULTS_PATH / 'results.xlsx'\n",
    "\n",
    "# Create a Pandas Excel writer using openpyxl as the engine\n",
    "with pd.ExcelWriter(excel_file_path, engine='openpyxl') as writer:\n",
    "    # Iterate over your CSV files\n",
    "    for csv_file in csv_file_paths:\n",
    "        # Use Path from pathlib to work with file paths\n",
    "        csv_path = Path(csv_file)\n",
    "        \n",
    "        # Extract the file name without the extension for the sheet name\n",
    "        sheet_name = csv_path.stem\n",
    "        \n",
    "        # Read each CSV file into a DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Write the DataFrame to a new sheet in the Excel file using the file name as the sheet name\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f'Merged CSV files into {excel_file_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
